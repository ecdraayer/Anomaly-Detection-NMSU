{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from   matplotlib.colors import LogNorm\n",
    "import numpy as np\n",
    "from   scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "f = open(\"data/Synthetic_Sin+anom/varNoise_fixedNumberAnomaliesfixedLength/SinusRW_Length_112000_AnomalyL_200_AnomalyN_60_NoisePerc_5.ts\", \"r\")\n",
    "data = f.read()\n",
    "data = (data.rstrip().split('\\n')) \n",
    "data = [float(i) for i in data]\n",
    "f.close()\n",
    "cpts = []\n",
    "f = open(\"data/Synthetic_Sin+anom/varNoise_fixedNumberAnomaliesfixedLength/SinusRW_Length_112000_AnomalyL_200_AnomalyN_60_NoisePerc_5_Annotations.txt\", \"r\")\n",
    "cpts = f.read()\n",
    "cpts = (cpts.rstrip().split('\\n')) \n",
    "cpts = [int(i) for i in cpts]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in NAB data\n",
    "f = open(\"data/realAWSCloudwatch/ec2_cpu_utilization_825cc2.csv\")\n",
    "data = f.read()\n",
    "print(data)\n",
    "#print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts = cpts[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.random.seed(555)\n",
    "import matplotlib.pyplot as plt\n",
    "import bocd\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open(\"Synthetic_Sin+anom/varNoise_fixedNumberAnomaliesfixedLength/SinusRW_Length_112000_AnomalyL_200_AnomalyN_60_NoisePerc_5.ts\", \"r\")\n",
    "#f = open(\"RealDatasets/MBA_ECG_801.ts\", \"r\")\n",
    "#f = open(\"lga.csv\", \"r\")\n",
    "test_signal = []\n",
    "with open('data/lga.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        if row[0] == 'LGA':\n",
    "            test_signal.append(row)\n",
    "        \n",
    "# test_signal = []\n",
    "# data = f.readlines()\n",
    "# for d in data:\n",
    "#     test_signal.append(d)\n",
    "test_signal = np.asarray(test_signal)\n",
    "print(len(test_signal))\n",
    "print(test_signal[0])\n",
    "test_signal = test_signal[:,-1]\n",
    "test_signal = test_signal[1:]\n",
    "test_signal = test_signal.astype(np.float)\n",
    "test_signal = np.flip(test_signal)\n",
    "\n",
    "test_signal = (test_signal - np.mean(test_signal)) / np.std(test_signal)\n",
    "print(test_signal[1])\n",
    "\n",
    "\n",
    "print(test_signal.shape)\n",
    "\n",
    "# test_signal = test_signal[1200:1400]\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/gdp_argentina.json') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "test_signal = data['series'][0]['raw']\n",
    "test_signal = np.asarray(test_signal)\n",
    "test_signal = test_signal.astype(np.float)\n",
    "\n",
    "test_signal = (test_signal - np.mean(test_signal)) / np.std(test_signal)\n",
    "print(test_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_signal[:100])\n",
    "# Generate test data\n",
    "# test_signal = np.concatenate(\n",
    "#     [np.random.normal(0.1, 1.0, 300), \n",
    "#      np.random.normal(2.0, 0.8, 300),\n",
    "#      np.random.normal(1.0, 0.5, 300),\n",
    "#      np.random.normal(3.0, 1.0, 300)])\n",
    "plt.plot(test_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize object\n",
    "bc = BayesianOnlineChangePointDetection(ConstantHazard(200), StudentT(mu=0, kappa=1, alpha=1, beta=1))\n",
    "\n",
    "# Online estimation and get the maximum likelihood r_t at each time point\n",
    "rt_mle = np.empty(test_signal.shape)\n",
    "for i, d in enumerate(test_signal):\n",
    "    if i >=0:\n",
    "        #print(i)\n",
    "        bc.update(test_signal[i-0:i+1])\n",
    "        rt_mle[i] = bc.rt\n",
    "        \n",
    "        #bc.update(test_signal[i])\n",
    "        #rt_mle[i] = bc.rt\n",
    "    else:\n",
    "        bc.update(d)\n",
    "        rt_mle[i] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.01,1,100]\n",
    "beta = [0.01,1,100]\n",
    "kappa = [0.01,1,100]\n",
    "L=0\n",
    "\n",
    "for a in alpha:\n",
    "    for b in beta:\n",
    "        for k in kappa:\n",
    "            # Initialize object\n",
    "            bc = BayesianOnlineChangePointDetection(ConstantHazard(50), StudentT(mu=0, kappa=k, alpha=a, beta=b))\n",
    "\n",
    "\n",
    "\n",
    "            # Online estimation and get the maximum likelihood r_t at each time point\n",
    "            rt_mle = np.empty(test_signal.shape)\n",
    "            for i, d in enumerate(test_signal):\n",
    "                if i >=L:\n",
    "                    #print(i)\n",
    "                    bc.update(test_signal[i-L:i+1])\n",
    "                    #print(bc.rt)\n",
    "                    rt_mle[i] = bc.rt\n",
    "\n",
    "                    #bc.update(test_signal[i])\n",
    "                    #rt_mle[i] = bc.rt\n",
    "                else:\n",
    "                    bc.update(d)\n",
    "                    rt_mle[i] = 0\n",
    "                    \n",
    "            print(\"alpha = \", a, \" Beta = \", b, \" kappa = \", k)\n",
    "            plt.plot(rt_mle)\n",
    "            plt.show()\n",
    "            # Plot data with estimated change points\n",
    "            plt.plot(test_signal, alpha=0.5, label=\"observation\")\n",
    "            index_changes = np.where(np.diff(rt_mle)<-1)[0]\n",
    "            plt.scatter(index_changes, test_signal[index_changes], c='green', label=\"change point\")\n",
    "            plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()\n",
    "plt.plot(rt_mle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data with estimated change points\n",
    "plt.plot(test_signal, alpha=0.5, label=\"observation\")\n",
    "index_changes = np.where(np.diff(rt_mle)<-1)[0]\n",
    "plt.scatter(index_changes, test_signal[index_changes], c='green', label=\"change point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class BayesianOnlineChangePointDetection:\n",
    "    def __init__(self, hazard, distribution):\n",
    "        self.hazard = hazard\n",
    "        self.distribution = distribution\n",
    "        self.T = 0\n",
    "        self.beliefs = np.zeros((1, 2),dtype=np.float64)\n",
    "        self.beliefs[0, 0] = 1.0\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.T = 0\n",
    "        self.beliefs = np.zeros((1, 2))\n",
    "        self.beliefs[0, 0] = 1.0\n",
    "\n",
    "    def _expand_belief_matrix(self):\n",
    "        rows = np.zeros((1, 2),dtype=np.float64)\n",
    "        self.beliefs = np.concatenate((self.beliefs, rows), axis=0)\n",
    "\n",
    "    def _shift_belief_matrix(self):\n",
    "        self.beliefs[:, 0] = self.beliefs[:, 1]\n",
    "        self.beliefs[:, 1] = 0.0\n",
    "\n",
    "    def update(self, x):\n",
    "        \n",
    "        \n",
    "        # Evaluate Predictive Probability (3 in Algortihm 1)\n",
    "        if type(x) is not np.ndarray:\n",
    "            self._expand_belief_matrix()\n",
    "\n",
    "            self.distribution.update_params(x)\n",
    "            # Update internal state\n",
    "            #print(len(self.beliefs))\n",
    "\n",
    "            self.T += 1\n",
    "        else:\n",
    "            self._expand_belief_matrix()\n",
    "\n",
    "            pi_t = self.distribution.pdf(x)\n",
    "            # Calculate H(r_{t-1})\n",
    "            h = self.hazard(self.rt)\n",
    "\n",
    "            # Calculate Growth Probability (4 in Algorithm 1)\n",
    "            #print(pi_t)\n",
    "            #print(len(self.beliefs))\n",
    "            #print(self.beliefs)\n",
    "            self.beliefs[1 : self.T + 2, 1] = self.beliefs[: self.T + 1, 0] * pi_t * (1 - h)\n",
    "\n",
    "            # Calculate Changepoint Probabilities (5 in Algorithm 1)\n",
    "            self.beliefs[0, 1] = (self.beliefs[: self.T + 1, 0] * pi_t * h).sum()\n",
    "\n",
    "            # Determine Run length Distribution (7 in Algorithm 1)\n",
    "            self.beliefs[:, 1] = self.beliefs[:, 1] / self.beliefs[:, 1].sum()\n",
    "\n",
    "            # Update sufficient statistics (8 in Algorithm 8)\n",
    "            self.distribution.update_params(x[-1])\n",
    "\n",
    "            # Update internal state\n",
    "            self._shift_belief_matrix()\n",
    "            self.T += 1\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def rt(self):\n",
    "        return np.where(self.beliefs[:, 0] == self.beliefs[:, 0].max())[0]\n",
    "\n",
    "    @property\n",
    "    def belief(self):\n",
    "        return self.beliefs[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Hazard:\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class ConstantHazard(Hazard):\n",
    "    def __init__(self, _lambda):\n",
    "        self._lambda = _lambda\n",
    "\n",
    "    def __call__(self, r):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          r: The length of the current run (np.ndarray or scalar)\n",
    "\n",
    "        Returns:\n",
    "          p: Changepoint Probabilities(np.ndarray with shape = r.shape)\n",
    "        \"\"\"\n",
    "        if isinstance(r, np.ndarray):\n",
    "            shape = r.shape\n",
    "        else:\n",
    "            shape = 1\n",
    "\n",
    "        return np.ones(shape) / self._lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "class Distribution:\n",
    "    def reset_params(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def pdf(self, x):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def update_params(self, x):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class StudentT(Distribution):\n",
    "    \"\"\" Generalized Student t distribution \n",
    "    https://en.wikipedia.org/wiki/Student%27s_t-distribution#Generalized_Student's_t-distribution\n",
    "\n",
    "    This setting corresponds to select\n",
    "      1: Gaussian distribution as a likelihood\n",
    "      2: normal-Gamma distribution as a prior for Gaussian\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mu=0, kappa=1, alpha=1, beta=1):\n",
    "        self.mu0 = np.array([mu],dtype=np.float64)\n",
    "        self.kappa0 = np.array([kappa],dtype=np.float64)\n",
    "        self.alpha0 = np.array([alpha],dtype=np.float64)\n",
    "        self.beta0 = np.array([beta],dtype=np.float64)\n",
    "        # We need the following lines to prevent \"outside defined warning\"\n",
    "        self.muT = self.mu0.copy()\n",
    "        self.kappaT = self.kappa0.copy()\n",
    "        self.alphaT = self.alpha0.copy()\n",
    "        self.betaT = self.beta0.copy()\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.muT = self.mu0.copy()\n",
    "        self.kappaT = self.kappa0.copy()\n",
    "        self.alphaT = self.alpha0.copy()\n",
    "        self.betaT = self.beta0.copy()\n",
    "\n",
    "    def pdf(self, x):\n",
    "        \"\"\" Probability Density Function\n",
    "        \"\"\"\n",
    "        #print(x)\n",
    "        #print()\n",
    "        #return stats.t.pdf(x, loc=self.muT, df=2 * self.alphaT, scale=np.sqrt(self.betaT * (self.kappaT + 1) / (self.alphaT * self.kappaT)),)\n",
    "        probs = []\n",
    "        for xd in x:\n",
    "            probs.append(stats.t.pdf(xd, loc=self.muT, df=2 * self.alphaT, scale=np.sqrt(self.betaT * (self.kappaT + 1) / (self.alphaT * self.kappaT)),))\n",
    "        \n",
    "        ans = np.zeros(len(probs[0]),dtype=np.float64)\n",
    "        for pro in probs:\n",
    "            for i in range(len(pro)):\n",
    "                ans[i] += pro[i]\n",
    "        ans /= len(probs[0])\n",
    "        #print(ans)\n",
    "        return ans\n",
    "        #return stats.t.pdf(x, loc=self.muT, df=2 * self.alphaT, scale=np.sqrt(self.betaT * (self.kappaT + 1) / (self.alphaT * self.kappaT)),)\n",
    "\n",
    "    def update_params(self, x):\n",
    "        \"\"\"Update Sufficient Statistcs (Parameters)\n",
    "\n",
    "        To understand why we use this, see e.g.\n",
    "        Conjugate Bayesian analysis of the Gaussian distribution, Kevin P. Murphyâˆ—\n",
    "        https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf\n",
    "        3.5 Posterior predictive\n",
    "        \"\"\"\n",
    "        self.betaT = np.concatenate(\n",
    "            [\n",
    "                self.beta0,\n",
    "                (self.kappaT + (self.kappaT * (x - self.muT) ** 2) / (2 * (self.kappaT + 1))),\n",
    "            ]\n",
    "        )\n",
    "        self.muT = np.concatenate([self.mu0, (self.kappaT * self.muT + x) / (self.kappaT + 1)])\n",
    "        self.kappaT = np.concatenate([self.kappa0, self.kappaT + 1])\n",
    "        self.alphaT = np.concatenate([self.alpha0, self.alphaT + 0.5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
